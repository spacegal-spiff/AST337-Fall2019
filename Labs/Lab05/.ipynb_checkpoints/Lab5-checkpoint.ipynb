{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Working with FITS Image Data and Manipulating Arrays\n",
    "\n",
    "## <u>Names:</u> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this lab is to create \"master\" calibration frames from raw calibration frames from the Amherst telescopes. Your future homework assignments will then involve applying these same methods to create calibrations for your own science data, so that you can work with calibrated science frames.\n",
    "\n",
    "To work with the calibration frames, we will learn how to navigate directories and work with arrays of FITS image data. Along the way, we will learn to use a few Unix tasks from within Python, and we will use and write a number of functions that we will later use outside of the Jupyter Notebook environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Downloading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to download a zipped folder with example FITS files from the Amherst telescope. This can be accessed on Google Drive here:\n",
    "\n",
    "https://drive.google.com/drive/folders/1-Y-Ivf1ZtUlbGwhMaYa5CJMbu1_jaTx8?usp=sharing\n",
    "\n",
    "Or can also be downloaded directly from Moodle (330 MB zip file). Place the zip file into your current directory with this notebook.\n",
    "\n",
    "**First**, unzip this file, which will decompress all of files into a single folder, `2019sep18`.\n",
    "\n",
    "To start working with different groups of images, it will be helpful to first organize all of those files into subfolders. We will import our usual Python modules and a few others needed for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The standard fare:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# Recall our use of this module to work with FITS files in Lab 4:\n",
    "from astropy.io import fits \n",
    "\n",
    "# This lets us use various Unix (or Unix-like) commands within Python:\n",
    "import os \n",
    "\n",
    "# We will see what this does shortly.\n",
    "import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Using Glob\n",
    "\n",
    "**glob** is an extremely useful function in Python. First, move into your data directory using `cd`, then `ls` to see the file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd 2019sep18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the following two cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_few_files = glob.glob('*NGC*.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_few_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does glob do? What kind of Python object is `a_few_files`, and what kinds of objects does it contain?   \n",
    "**Answer**: \n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    "Now use glob to create a new variable, `all_fits`, that contains the names of **all** of the FITS files in your directory. We will use this variable a number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish this cell\n",
    "\n",
    "all_fits = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Iterating to View Header Info\n",
    "\n",
    "We now would like to take all of our FITS files and sort them into subfolders based on the type of image, e.g., calibration, science, standard star, etc. Helpfully, the file names include some clues about what sort of files we have. However, if you remember from our observing nights and log sheets, not all of the file names are always correct. This can happen _quite easily_ at the telescope, because camera software programs typically have various automated ways of naming files (often different from observatory to observatory) and sometimes require the user to remember to change settings while observing.\n",
    "\n",
    "(To avoid this, some observatories name their files in a uniform way, like \"Image_00001.fits\" or with a time/date stamp, like \"NACO_2017-10-05T00:04:18.fits\", which provide unique identifiers.)\n",
    "\n",
    "Therefore, to check our data and sort it accurately, we are going to rely on the FITS **header information** instead of the filenames themselves. You can imagine that this is also more reliable if you have 1000's of FITS files to work with! \n",
    "\n",
    "We'll look at the header information first to get a sense of the type of files we're dealing with. There are a couple different ways we can look at FITS headers; in Lab 4, we used `fits.open`, which is very versatile. Here, we'll use two new functions to quickly view the header and data:\n",
    "\n",
    "`fits.getheader('filename')`\n",
    "\n",
    "and \n",
    "\n",
    "`fits.getdata('filename')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell to save the header of the zeroth (that is, the first) FITS file in the all_fits list:\n",
    "\n",
    "test_header = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, view the header info here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use our new variable to view specific header **keyword values**, such as the image type, or object:  \n",
    "(\"IMAGETYP\" and \"OBJECT\", since FITS files can only have 8 character keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_header['IMAGETYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_header['OBJECT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use `for` loops to iterate over each FITS file in our directory, so we can quickly see what kinds of FITS files we have based on keyword. \n",
    "\n",
    "If iteration is newer to you (or you'd like a brief refresher), check out the other notebook in the main directory ('Unix_Programming_Refresher') for some quick reference exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example for loop that provides all of the image types. \n",
    "# (1) Run this function to view all of the 'IMAGETYP' values, then\n",
    "# (2) Edit and re-run the function to view all of the 'OBJECT' values, then \n",
    "# (3) Edit and re-run once more to view a different header keyword value of your choice.\n",
    "\n",
    "for filename in all_fits:\n",
    "    header = fits.getheader(filename)\n",
    "    filetype = header['IMAGETYP']\n",
    "    print(filetype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Sorting Function\n",
    "\n",
    "Because data taken in different filters and with different exposure times require matching calibration files, our goal is to create the following directory structure:\n",
    "\n",
    "<img src=\"./folder_flowchart.png\" width='50%'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a generic function that:\n",
    "\n",
    "(1) takes as input:  \n",
    "* the name of a single FITS file,  \n",
    "* the desired folder name,  \n",
    "* the desired type of FITS file,   \n",
    "* the header keyword to match the FITS file type\n",
    "\n",
    "(2) reads in the file's header information,  \n",
    "\n",
    "(3) reads in the file's type based on the keyword  \n",
    "\n",
    "(4) checks if the desired folder name exists, and makes a new directory if it doesn't  \n",
    "\n",
    "(5) checks if the file's type matches the desired type of fitsfile  \n",
    "\n",
    "(6) moves the file into the new or existing folder, _if_ the file matches the right file type.\n",
    "\n",
    "<br>\n",
    "\n",
    "We've provided a function that does all of these steps, but lacks a docstring. You'll be using this function multiple times, so discuss within your group exactly how the function works, then update the docstring and add comments within the function (using #)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filesorter(filename, foldername, fitskeyword_to_check, keyword):\n",
    "    '''\n",
    "    Edit this docstring to describe the function purpose and use.\n",
    "    '''\n",
    "    # Add your own comment explaining this if-else statement:\n",
    "    if os.path.exists(filename):\n",
    "        pass\n",
    "    else:\n",
    "        print(filename + \" does not exist or has already been moved.\")\n",
    "        return\n",
    "    \n",
    "    header = fits.getheader(filename)\n",
    "    fits_type = header[keyword]\n",
    "    \n",
    "    # Add your own comment explaining this if-else statement:\n",
    "    if os.path.exists(foldername):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Making new directory: \" + foldername)\n",
    "        os.mkdir(foldername)\n",
    "    \n",
    "    # Add your own comment explaining this if statement:\n",
    "    if fits_type == fitskeyword_to_check:\n",
    "        destination = foldername + '/'\n",
    "        print(\"Moving \" + filename + \" to: ./\" + destination + filename)\n",
    "        os.rename(filename, destination + filename)  \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test out the `filesorter` function for a single file, **20190918.00000002.flat.fit**. We know this should be a calibration file from the name, but the 'calibration' folder doesn't exist yet, and we can test whether or not it is actually a 'cal' file by checking the 'CALTYPE' keyword from the FITS file, to see if it matches the string 'cal'. \n",
    "\n",
    "Execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesorter('20190918.00000002.flat.fit', 'calibration', 'cal', 'CALTYPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Sort all the calibration data\n",
    "\n",
    "The loops in the following cells go through each file in all_fits, and applies `filesorter` to each file based on the choice of folder name ('calibration'), keyword value, and keyword. You don't need to change any of the cells in this section, but **make sure you understand how the filesorter function is working within the loop, since it will come in handy for your future data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to sort calibration data here:\n",
    "for fitsfile in all_fits:\n",
    "    filesorter(fitsfile, 'calibration', 'cal', 'CALTYPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, move into the calibration folder you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd calibration/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-glob the fits files in the calibration director to a new variable\n",
    "\n",
    "cal_files = glob.glob('*.fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, the same for-loop structure is used to make subdirectories for biasframes, darks, and flats. We won't be using 'CALTYPE' as the keyword, since that's a more generic category -- instead, we're matching on the keyword \"IMAGETYP\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to sort flats:\n",
    "for fitsfile in cal_files:\n",
    "    filesorter(fitsfile, 'flats', 'Flat Field', 'IMAGETYP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to sort bias frames:\n",
    "for fitsfile in cal_files:\n",
    "    filesorter(fitsfile, 'biasframes', 'Bias Frame', 'IMAGETYP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to sort dark frames:\n",
    "for fitsfile in cal_files:\n",
    "    filesorter(fitsfile, 'darks', 'Dark Frame', 'IMAGETYP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, list the contents of each subfolder to check and make sure things moved correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls biasframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls darks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting by filter or exposure time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two final steps to consider in our sorting process. The flatfields were taken in different filters, but right now they are all lumped together into one folder. Similarly, we have darks of different exposure times, but they too are lumped together into one big dark frame folder. \n",
    "\n",
    "In the following cells, go into the darks and flats folders and use the same loop approach as above to sort the files as follows:\n",
    "\n",
    "* darks into separate subfolders of '2s', '5s', '7s', and '120s' folders (you will have to find the appropriate keywords)\n",
    "* flats into separate subfolders of 'Red', 'Visual', or 'Blue' (again, find the appropriate keyword to match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the darks into their respective subfolders (feel free to add cells as needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the flats into their respective subfolders (feel free to add cells as needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now your entire 2019sep18 calibration directory should be structured as in the flowchart above.\n",
    "\n",
    "**Pause** here and check with Kim/Sarah to make sure the procedure makes sense and everything sorted correctly before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "\n",
    "## Part 2: Working with Array Data!\n",
    "\n",
    "Now that our calibration data are all sorted into folders, we'll start to work with the raw frames to make the master calibration files.\n",
    "\n",
    "## 2.1 Bias Frames\n",
    "\n",
    "It's simplest to create a master bias frame first, so we'll start with the bias frames. Change directories into your newly-created `biasframes` folder and `ls` to make sure everything has transferred correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd biasframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining bias frame properties\n",
    "\n",
    "The first thing we'll need to do, as before, is to use glob to create a new list of only bias frames to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete to create a new bias frame list:\n",
    "\n",
    "biasfiles = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in your reading and in lecture, what we ultimately want is a median combination of all of the individual bias frames. So we will create a stack of bias images, and then we will take the median values at each pixel location in the stack to create the final combined frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete: Define a new variable, n, and determine how many bias files there are (length of biasfiles):\n",
    "n = \n",
    "\n",
    "# And use fits.getdata to read in the data for only the first bias frame (the zeroth element of the bias list):\n",
    "first_bias_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly display the bias image here, showing only values around its median pixel value. It doesn't look very interesting - **mostly** just a noise pattern, which is what we'd expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(first_bias_data, vmin=1030, vmax=1050)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, our FITS images are 2-D, and we will be working with arrays of various dimensions -- not all FITS images are the same size (e.g. 1024 x 1024). In `numpy`, we can define arrays of various sizes as follows. Execute the cell, and Jupyter will print the formatted version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9],[10,11,12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the shape of the array, we can simply use the .shape command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9],[10,11,12]])\n",
    "test_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use this method to determine the dimensions of the first bias image and define them as new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete to get the dimensions of first_bias_data, then check the values\n",
    "\n",
    "imsize_y, imsize_x = \n",
    "imsize_y, imsize_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bias files are there? (Use the empty cell below to check.)  \n",
    "**Answer**:\n",
    "\n",
    "What are the dimensions of the first bias frame?   \n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine # of bias files here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a blank 3-D array and adding images to it\n",
    "\n",
    "In order to take the median value of the stacked bias frames, we'll need to insert them into a larger array first. We can do this by creating a \"blank\" 3-D array filled with zero values with dimensions of (y dimension, x dimension, number of images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blank stack of arrays to hold each of the frames\n",
    "# **IMPORTANT** Note that Y is listed first! This is a pecularity in how python reads arrays:\n",
    "\n",
    "biasarray = np.zeros((imsize_y, imsize_x , n)) \n",
    "\n",
    "# Now check the shape of our new \"blank\" array:\n",
    "biasarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, check what the values in the biasarray look like now:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fill in our empty array of zeros, by making a **stack** of bias frames by adding the data from each of the FITS files into the \"blank\" stack, one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert each bias frame into a three dimensional stack, one by one:\n",
    "\n",
    "for ii in range(0, n):\n",
    "    im = fits.getdata(biasfiles[ii])\n",
    "    biasarray[:,:,ii] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the biasarray values look now?\n",
    "biasarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the median and saving the master bias:\n",
    "\n",
    "Now the final steps to create a master bias frame are to:\n",
    "\n",
    "(1) take the median of the 3-D array, along the appropriate axis, which will collapse the image to a regular two dimensional array,\n",
    "\n",
    "and \n",
    "\n",
    "(2) save this new 2-D array -- the master bias -- as a brand-new fits file with a new name, giving it the same header as the the first bias image for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the median of the 3-D stack: \n",
    "med_bias = np.median(biasarray, axis = 2) # axis=2 means stack along the *third* axis, since python is zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And get the header for the first image in the list:\n",
    "biasheader = fits.getheader(biasfiles[0])\n",
    "\n",
    "# Define a name for the new output FITS file:\n",
    "master_bias = 'Master_Bias.fit'\n",
    "\n",
    "# Save your new FITS file!\n",
    "fits.writeto(master_bias, med_bias, biasheader, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What inputs does the `fits.writeto` function require to save a new FITS files?  \n",
    "**Answer:**\n",
    "\n",
    "\n",
    "The final step is to check the final master bias frame to see if it appears normal. In DS9, open up a single raw calibration bias frame as well as the the new Master_Bias.fit that you just created. \n",
    "\n",
    "How do the two compare? Do the pixel values seem reasonable? Do the dimensions of the image make sense?  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Combination Function\n",
    "For ease of use, let's write all of those proceeding steps into a single function that we can re-use later. Edit the docstring below and add comments for each step that describe what the function is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediancombine(filelist):\n",
    "    '''\n",
    "    Edit this docstring accordingly!\n",
    "    '''\n",
    "    # Add your own comment describing this step\n",
    "    n = len(filelist)\n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n)) \n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        fits_stack[:,:,ii] = im\n",
    "        \n",
    "    # Add your own comment describing this step        \n",
    "    med_frame = np.median(fits_stack, axis = 2)\n",
    "    \n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our step to create a median of all the bias frames is much simpler! \n",
    "median_bias = mediancombine(biasfiles)\n",
    "\n",
    "# Below, how would you save the new median_bias frame as a FITS file? \n",
    "# Complete the function below and save the duplicate master bias as \"Backup_MasterBias.fit\")\n",
    "\n",
    "fits.writeto()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One last note on the master bias** -- we will need to determine the path to the Master_Bias.fit file, because we will use functions that call it from different folders. We can do this using os.getcwd (get **c**urrent **w**orking **d**irectory) and adding a string with the filename, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bias_path = os.getcwd() + '/Master_Bias.fit'\n",
    "master_bias_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Dark Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias subtracting the darks:\n",
    "\n",
    "We want to median combine our darks, but contribution from bias is present in every image taken, so our first step after creating a master bias frame is always to subtract it from every other image. Array subtraction is more straightforward -- as long as two arrays have the same dimension, they can be subtracted from one another on a pixel-by-pixel basis.\n",
    "\n",
    "Below, write a generalized function below that subtracts Master_Bias.fit from a single frame. Your function should: \n",
    "\n",
    "1) take a FITS file name and path to the master bias as inputs,   \n",
    "2) load in the data for the file to be calibrated,  \n",
    "3) loads in the header information for that file,  \n",
    "4) loads in the data for Master_Bias.fit as a variable (remember, it's located in a different folder than where you are now! Hence the second input),  \n",
    "5) subtract the bias from the input FITS file, and  \n",
    "6) save (writeto) the new bias-subtracted FITS file with a modified name (e.g., 20190918.00000099.A.Dark.fit would become b_20190918.00000099.A.Dark.fit, to denote that bias-subtraction has been performed).\n",
    "\n",
    "Once you've written and tested your function, you will apply it to all of the dark frames.\n",
    "\n",
    "The first step is to move into the `darks/120s` directory from your current location and glob a subset of the dark files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../darks/120s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darkfiles = glob.glob('*fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your bias subtraction function here:\n",
    "\n",
    "def bias_subtract(filename, path_to_bias):\n",
    "    '''\n",
    "    Add your docstring here.\n",
    "    '''\n",
    "    # Your code goes here.\n",
    "    \n",
    "    \n",
    "    \n",
    "    fits.writeto('b_' + filename, ) # finish this code too to save the FITS\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out your function on an individual frame (remember, we defined \"master_bias_path\" just before Section 2.2:\n",
    "\n",
    "bias_subtract('20190918.00000099.A.Dark.fit', master_bias_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? You can test whether the bias subtraction worked by viewing the before/after frames in DS9. How can you tell if the subtraction was successful?  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write and execute a for loop that subtracts the bias from each of the dark frames. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have twice the number of dark frames in your directory, half of which have the prefix 'b\\_'. These are the frames we want to median combine into the master dark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use the `mediancombine` function from earlier to combine all of the _bias-subtracted_ dark frames into a single master dark. We will call it *Master_Dark_120s.fit*, since dark frames need to match exposure times of the other kinds of images (flats, science frames).\n",
    "\n",
    "**Be careful** using glob to select only the darks that have been bias-subtracted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your lines of code here: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the master dark compare to a single raw dark frame? Take a look in DS9 and compare:  \n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the process for the other dark exposure times, to create 2s, 5s, and 7s darks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, cd into the other dark subfolders and create master darks for each of the other exposure times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2s master dark (add cells where necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 5s master dark (add cells where necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 7s master dark (add cells where necessary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Flat Fields\n",
    "\n",
    "The final master calibration we want to create is a master flat field (flat). Features that appear in the flats are highly specific to the filters in which they are taken -- so we will end up with three master flat fields. Therefore, our first steps will be to cd into the flats folder, glob files, and run our `filesorter` function to make the three flat subfolders in our diagram, 'Vband', 'Rband', and you will edit the loop to include \"Bband\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../flats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by filter into new subfolders below, using the filesorter function. \n",
    "# Add an additional line to your loop to sort the B-band flats too:\n",
    "\n",
    "flatfiles = glob.glob('*fit')\n",
    "\n",
    "for filename in flatfiles:\n",
    "    filesorter(filename, 'Vband', 'V', 'FILTER')\n",
    "    filesorter(filename, 'Rband', 'R', 'FILTER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work just with Vband for now, so go into that directory, and you'll work with the other two filter reductions in the homework. Like always, our first step is to subtract the master bias. Do this below for all of the files, using your `bias_subtract` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Vband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias-subtract the flat fields:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dark subtract the flat fields:\n",
    "\n",
    "Now, we will want to subtract the dark contribution from the flat fields. This can be accomplished by creating a new function below, `dark_subtract`, that looks very much like your `bias_subtract` function. \n",
    "\n",
    "> * Most importantly, make sure that the dark you subtract matches the exposure time of the flat fields! \n",
    "\n",
    "Use glob and a for loop to check the flat exposure times in the cell below. What is/are the value(s)?  \n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the flat field exposure times here for the files in your directory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since dark current accumulates with time, you need to ensure that the exposure time of your dark frames **matches** that of the frames you want to subtract dark current from. Oftentimes you can *scale* a longer exposure dark, say a 60s or 120s master dark, to approximate different exposure times, or you can use darks that were taken with exactly the same exposure time. \n",
    "\n",
    "For our purposes, we have darks taken at the matching exposure times for the flats and science. \n",
    "\n",
    "When you save your dark-subtracted FITS file, be sure to add another prefix to the file name, and it's important to only dark subtract the bias-subtracted images. For example, this would change 'b_20190918.00000021.flat.fit' to 'db_20190918.00000021.flat.fit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"cp\" to copy the other master darks to your \"darks\" directory in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When you save your dark-subtracted flat images, be sure to add another prefix to the file name, and it's important to only dark subtract the already bias-subtracted images. For example, your function should subtract the dark current from 'b_20190918.00000021.flat.fit', then make a new FITS file called 'db_20190918.00000021.flat.fit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your dark subtraction function here:\n",
    "\n",
    "def dark_subtract(filename, path_to_dark):\n",
    "    '''\n",
    "    Add your docstring here.\n",
    "    '''\n",
    "    \n",
    "    # Your code goes here.\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use your new dark_subtraction function and a loop to dark subtract the bias-subtracted flat fields:\n",
    "\n",
    "\n",
    "# Did that work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Making a Master Flat Field\n",
    "\n",
    "The final step in creating master calibrations is to make a master flat field. Before we median combine into a single image, we want to divide each individual flat by its median *pixel value*, such that all the pixel values in each frame have values of approximately ~1.0 -- that is, we want to **normalize** them. Only then do we median combine the stack of normalized flat fields to create a master flat.\n",
    "\n",
    "We can do this in a single function by editing the `mediancombine` function from earlier, and simply adding a single new line of code. \n",
    "\n",
    "In line 11 below, add this extra line of code that normalizes `im` before adding it to the 3D array of fits_stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_combine_flats(filelist):\n",
    "    '''\n",
    "    Edit this docstring accordingly!\n",
    "    '''\n",
    "    # Add your own comment describing this step\n",
    "    n = len(filelist)\n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "    \n",
    "    # Add your own comment describing this step\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n))\n",
    "    \n",
    "    # Add your own comment describing this loop\n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        norm_im =  # finish new line here to normalize flats\n",
    "        fits_stack[:,:,ii] = norm_im\n",
    "        \n",
    "    # Add your own comment describing this step    \n",
    "    med_frame = np.median(fits_stack, axis=2)\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, run `norm_combine_flats` on your list of dark-subtracted, bias-subtracted frames (only 5 images!), and then check the values of the output to ensure they're close to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your list of files first, as usual:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply norm_combine_flats to that list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the output of the variable you defined in the previous cell to check the values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a final step, finish the code below to save the master flat as a new fits file (Master_Flat_Vband.fit),\n",
    "# with the header taken from the first frame in the flat list.\n",
    "\n",
    "flat_header =\n",
    "\n",
    "fits.writeto('Master_Flat_Vband.fit', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine your master flat file in DS9 and compare it to one of the raw flat frames. What do you notice about the two frames, qualitatively and quantitatively?  \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
